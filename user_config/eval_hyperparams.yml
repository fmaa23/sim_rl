---
rl_params:
  num_episodes: 5
  
  threshold: 10

  num_epochs: 10
  
  time_steps: 10
  
  target_update_frequency: 100
  
  batch_size: 16
  
  num_sim: 5000
  
  tau: 0.001
  
  learning_rate: 0.1
  
  discount: 0.2
  
  planning_steps: 10
  
  epsilon: 0.2
  
  epsilon_f: 0.1
  
  actor_lr: 0.1

state_exploration_params:
  num_sample: 50
  
  w1: 0.5
  
  w2: 0.5
  
  epsilon_state_exploration: 1

  reset: False

  reset_frequency: 2

  num_output: 5

  moa_window: 5

  output_json: True

  output_histogram: True

  output_coverage_metric: True

network_params:
  actor:
    - 32
    - 32
  
  critic:
    - 64
    - 64
  
  reward_model:
    - 64
    - 64
  
  next_state_model:
    - 64
    - 64