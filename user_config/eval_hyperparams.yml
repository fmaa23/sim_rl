---
rl_params:
  num_episodes: 50
  
  threshold: 10

  num_epochs: 100
  
  time_steps: 100

  num_train_agent: 10
  
  num_sim: 100

  buffer_size: 100000
  
  tau: 0.5
  
  critic_lr: 0.01

  actor_lr: 0.001
  
  discount: 0.2
  
  planning_steps: 10
  
  epsilon: 0.2
  
  epsilon_f: 0.1

state_exploration_params:

  num_sample: 100
  
  w1: 0.5
  
  w2: 0.5
  
  epsilon_state_exploration: 1

  reset: False

  reset_frequency: 2

  num_output: 5

  moa_window: 5

  output_json: True

  output_histogram: False

  output_coverage_metric: True

network_params:
  actor:
    - 64
    - 64
  
  critic:
    - 64
    - 64
  
  reward_model:
    - 64
    - 64
  
  next_state_model:
    - 64
    - 64